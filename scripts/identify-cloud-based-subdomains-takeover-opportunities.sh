#!/bin/bash
#############################################################################################
# Script to find, as much as possible, subdomains of a company pointing to a cloud service 
# provider like HEROKU/RENDER/etc. via a CNAME DNS records on the company DNS domain records.
# The objective is to identify any subdomain potentially prone to a subdomain hijacking 
# due to the fact that the app/account on the cloud service provider was removed BUT NOT the 
# associated CNAME records.
#
# Reference:
#    https://github.com/EdOverflow/can-i-take-over-xyz/blob/master/README.md
#
# Requirements in terms of software:
#	https://github.com/PentestPad/subzy
#	https://github.com/d3mondev/puredns
# 	apt install wget curl jq dnsutils whois
# 
# Note:
#	System command was used, for DNS related work, because it was more reliable than 
#	"github.com/projectdiscovery/dnsx" when the container was used within the 
#	context of an VPN connection on the docker host.
#
# Remark:
#	Focus was made on reliability of data retrieved over the performance aspects.
#############################################################################################

# Constants
CRTSH_DATA_FILE="/tmp/crtshdata.json"
WORK_FILE_IN="/tmp/work-in.txt"
WORK_FILE_OUT="/tmp/work-out.txt"
WORK_FILE_SWP="/tmp/work-in.swp"
CSV_FILE="subdomains.csv"
CSV_FILE_HEADERS="Provider,Subdomain,CNAME"
TRACE_FILE="/tmp/trace.out"
THREAD_COUNT=10
DNS_RATE_LIMIT_COUNT=100
DNS_WORDLIST="/tools/sec-lists/Discovery/DNS/namelist.txt"
GO_BIN_HOME="/root/go/bin"

# Entry point
if [ "$#" -lt 1 ]; then
    script_name=$(basename "$0")
    echo "Usage:"
    echo "   $script_name [COMPANY_BASE_DOMAIN]"
    echo ""
    echo "Call example:"
    echo "    $script_name righettod.eu"
    exit 1
fi

# Utility functions
function write_step(){
    echo -e "\e[93m$1\e[0m"
}

function validate_downloaded_data_files(){
	status=0
	counter=$(grep -Fc "$BASE_DOMAIN" $CRTSH_DATA_FILE)
	if [ $counter -eq 0 ]
	then
		status=1
	fi
	return $status
}

function process_subdomain(){
	subdomain=$1
	for cname in $(dig +time=5 +tries=2 +retry=2 +short +notrace -t CNAME @8.8.8.8 $subdomain)
	do
		if [ -z "$cname" ]
		then
			continue
		fi
        #echo ">>>> $cname"
		is_azure=$(echo "$cname" | grep -Eic "(AZURE|MICROSOFT|WINDOWS|OUTLOOK|CLOUDAPP)")
		is_aws=$(echo "$cname" | grep -Eic "(AWS|AMAZON)")
		is_gcp=$(echo "$cname" | grep -Eic "(GCP|GOOGLE)")
        is_digitalocean=$(echo "$cname" | grep -Fic "DIGITALOCEAN")
        is_github=$(echo "$cname" | grep -Fic "GITHUB")
        is_gitlab=$(echo "$cname" | grep -Fic "GITLAB")
        is_render=$(echo "$cname" | grep -Fic "RENDER.COM")
		provider="NONE"
		if [ $is_azure -gt 0 ]
		then
			provider="AZURE"
		elif [ $is_aws -gt 0 ]
		then
			provider="AWS"
		elif [ $is_gcp -gt 0 ]
		then
			provider="GCP"			
		elif [ $is_digitalocean -gt 0 ]
		then
			provider="DIGITALOCEAN"			
		elif [ $is_github -gt 0 ]
		then
			provider="GITHUB"			
		elif [ $is_gitlab -gt 0 ]
		then
			provider="GITLAB"			
		elif [ $is_render -gt 0 ]
		then
			provider="RENDER"			
		fi                         
		if [ "$provider" != "NONE" ]
		then
			print_result_line "$provider" "$subdomain" "$cname"
		fi	
	done	
}

function print_result_line(){
	provider=$1
	subdomain=$2
	cname=$3	
	printf "[%-5s] %-15s => %s\n" "$provider" "$subdomain" "$cname"
	echo "$provider,$subdomain,$cname" >> $CSV_FILE
}

function print_file_line_count(){
	fle=$1
	count=$(wc -l $fle | cut -d' ' -f1)
	echo "Subdomains found: $count."
}

# Working context
BASE_DOMAIN="$1"

# Main processing
rm $WORK_FILE_IN $WORK_FILE_OUT $TRACE_FILE 2>/dev/null
echo $CSV_FILE_HEADERS > $CSV_FILE
write_step "[Discovery] Download Certificate Transparency data ..."
curl -sk --output $CRTSH_DATA_FILE "https://crt.sh/?q=%25.$BASE_DOMAIN&output=json"
validate_downloaded_data_files
validity_check=$?
if [ $validity_check -ne 0 ]
then
    echo "Data files were not correctly downloaded, please retry (status code is $validity_check)."
    exit 1		
fi
cat $CRTSH_DATA_FILE | jq -r ".[].common_name" | grep -iv "\.local$" | grep -Fv "*" > $WORK_FILE_IN
cat $CRTSH_DATA_FILE | jq -r ".[].name_value" | grep -iv "\.local$" | grep -Fv "*" | grep -Fv "@" >> $WORK_FILE_IN
cat $WORK_FILE_IN | sort -u > $WORK_FILE_OUT
mv $WORK_FILE_OUT $WORK_FILE_IN
print_file_line_count $WORK_FILE_IN
write_step "[Discovery] Find additional subdomains of '$BASE_DOMAIN' via DNS discovery ..."
$GO_BIN_HOME/puredns bruteforce "$DNS_WORDLIST" "$BASE_DOMAIN" --write $WORK_FILE_OUT --rate-limit-trusted $DNS_RATE_LIMIT_COUNT --rate-limit $DNS_RATE_LIMIT_COUNT --quiet >/dev/null
cat $WORK_FILE_IN $WORK_FILE_OUT| sort -u > $WORK_FILE_SWP
mv $WORK_FILE_SWP $WORK_FILE_IN
rm $WORK_FILE_OUT
print_file_line_count $WORK_FILE_IN
write_step "[Discovery] Search for potential vulnerable subdomains using 'subzy' ..."
$GO_BIN_HOME/subzy update
$GO_BIN_HOME/subzy run --https --output $WORK_FILE_OUT --targets $WORK_FILE_IN --concurrency $THREAD_COUNT > $TRACE_FILE
cat $WORK_FILE_OUT | jq -r '.[] | select(.status != "not vulnerable") | .subdomain' | sort -u > $WORK_FILE_IN
print_file_line_count $WORK_FILE_IN
write_step "[Validate ] Validate potential vulnerable subdomains identified ..."
while IFS= read -r subdomain
do
	process_subdomain $subdomain
done < "$WORK_FILE_IN"
write_step "[Gathering] Data stored into CSV file '$CSV_FILE'."
